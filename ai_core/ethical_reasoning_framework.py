# -*- coding: utf-8 -*-
"""
ä¼¦ç†æ¨ç†æ¡†æ¶ - (å·²ä¿®å¤) ä¸€ä¸ªå…·å¤‡ç¤¾äº¤èƒ½åŠ›çš„ã€å¯å‚ä¸ç¾¤ä½“é“å¾·æ¼”åŒ–çš„æ™ºèƒ½ä½“
"""

import logging
import random
from typing import Dict, Any, List, Tuple, TYPE_CHECKING

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from .models.ethical_case import EthicalCase, ActionOption
from .models.moral_genome import MoralGenome
from .moral_calculus import calculate_moral_vector

# å¯¼å…¥è¡Œä¸ºæ ‘æ¡†æ¶
from .behavior_tree.node import Node
from .behavior_tree.composites import Selector, Sequence
from .action_library import ActionIdle, ActionExecuteChosen

# é¿å…åœ¨è¿è¡Œæ—¶äº§ç”Ÿå¾ªç¯å¯¼å…¥
if TYPE_CHECKING:
    from .society.ai_entity_manager import AIEntityManager
    from .society.moral_message import MoralMessage
    from .moral_profiler import MoralProfiler

logger = logging.getLogger(__name__)

CULTURAL_INFLUENCE_THRESHOLD = 0.6
CULTURAL_ADJUSTMENT_FACTOR = 0.3

class ThoughtStream:
    """ä¸€ä¸ªç®€å•çš„ç±»ï¼Œç”¨äºè®°å½•AIè¿è´¯çš„æ€è€ƒè¿‡ç¨‹ã€‚"""
    def __init__(self):
        self.thoughts: List[str] = []
    def add(self, thought: str, depth: int = 0): self.thoughts.append(f"{'  ' * depth}{thought}")
    def get_process(self) -> str: return "\n".join(self.thoughts)
    def clear(self): self.thoughts.clear()

class EthicalAgent:
    """
    ä¸€ä¸ªèƒ½å¤Ÿå‚ä¸ç¤¾ä¼šäº’åŠ¨çš„ã€å¯æ¼”åŒ–çš„ä¼¦ç†æ™ºèƒ½ä½“ã€‚
    """

    def __init__(self, name: str, profiler: 'MoralProfiler', entity_manager: 'AIEntityManager'):
        self.name = name
        self.profiler = profiler
        self.entity_manager = entity_manager
        self.architecture = "social_context_aware_pareto_genetic"
        # ä¿®å¤AttributeError: å°†thought_streamæå‡ä¸ºå¯¹è±¡å±æ€§
        self.thought_stream = ThoughtStream()

        initial_intuitions = {
            "utilitarian": 0.5, "deontological": 0.5, "virtue": 0.5,
            "power_distance": 0.5, "individualism": 0.5, "uncertainty_avoidance": 0.5,
        }
        self.genome = MoralGenome(initial_intuitions)

        # çŠ¶æ€
        self.is_thinking = False
        self.current_dilemma: EthicalCase | None = None
        self.chosen_action: ActionOption | None = None
        self.message_inbox: List['MoralMessage'] = []

        self.behavior_tree: Node = self._build_behavior_tree()
        logger.info(f"ç¤¾ä¼šæ€§ä¼¦ç†æ™ºèƒ½ä½“ {self.name} å·²åˆ›å»ºã€‚")

    def _build_behavior_tree(self) -> Node:
        return Selector(name="Root Logic", children=[
            Sequence(name="Execute Chosen Action", children=[
                ActionExecuteChosen(name="Perform Chosen Action")
            ]),
            ActionIdle(name="Perform Idle")
        ])

    def tick(self):
        """AIçš„ä¸»â€œå¿ƒè·³â€ï¼Œç°åœ¨åŒ…å«ç¤¾äº¤å¤„ç†ã€‚"""
        print(f"\n--- {self.name}'s Tick ---")
        self._process_social_influence()
        if self.is_thinking:
            self._resolve_dilemma()
        self.behavior_tree.tick(self)

    def broadcast_moral_message(self, action: ActionOption):
        """åœ¨æ‰§è¡Œä¸€ä¸ªè¡ŒåŠ¨åï¼Œå‘ç¤¾ä¼šå¹¿æ’­ä¸€ä¸ªé“å¾·æ¶ˆæ¯ã€‚"""
        message = self.entity_manager.create_message_from_action(self, action)
        print(f"   ğŸ“£ [ç¤¾äº¤] {self.name} å‘ç¤¾ä¼šå¹¿æ’­äº†ä¸€ä¸ªé“å¾·äº‹ä»¶: '{action.name}'")
        self.entity_manager.broadcast_message(message)

    def _process_social_influence(self):
        """å¤„ç†æ”¶ä»¶ç®±ä¸­çš„é“å¾·æ¶ˆæ¯ï¼Œå¹¶å†³å®šæ˜¯å¦è¢«å½±å“ã€‚"""
        if not self.message_inbox:
            return
        
        print(f"   ğŸ“¬ [ç¤¾äº¤] {self.name} æ­£åœ¨æ£€æŸ¥é‚®ç®± ({len(self.message_inbox)}æ¡æ–°æ¶ˆæ¯)... ")
        for message in self.message_inbox:
            probability = self.entity_manager.contagion_system.calculate_contagion_probability(message.original_sender, self, message)
            print(f"     - è¯„ä¼°æ¥è‡ª '{message.original_sender.name}' çš„æ¶ˆæ¯... è¢«è¯´æœçš„æ¦‚ç‡: {probability:.2f}")

            if random.random() < probability:
                print(f"       âœ¨ {self.name} è¢« '{message.original_sender.name}' çš„è§‚ç‚¹è¯´æœäº†ï¼")
                self.entity_manager.evolver.evolve_towards(self, message.moral_content)
        
        self.message_inbox.clear()

    def _resolve_dilemma(self):
        if not self.current_dilemma: return
        self.thought_stream.clear()
        self.thought_stream.add(f"ğŸ¤” {self.name} æ­£åœ¨è¿›è¡Œå¤šç›®æ ‡é“å¾·æƒè¡¡...")
        
        action_vectors = []
        for action in self.current_dilemma.action_options:
            vector = calculate_moral_vector(action, self.current_dilemma)
            action_vectors.append((action, vector))
            self.thought_stream.add(f"æ–¹æ¡ˆ '{action.name}' çš„é“å¾·å‘é‡: {vector}", 1)

        pareto_front = self._find_pareto_front(action_vectors)
        self.thought_stream.add(f"å¸•ç´¯æ‰˜æœ€ä¼˜è§£é›†: {[action.name for action, _ in pareto_front]}", 1)

        self.chosen_action = self._select_from_pareto_front(pareto_front)
        self.thought_stream.add(f"åŸºå› /æ–‡åŒ–é©±åŠ¨é€‰æ‹©: æœ€ç»ˆé€‰æ‹© '{self.chosen_action.name}'", 1)
        
        # å†³ç­–å®Œæˆåï¼Œä¸å†æ‰“å°ï¼Œè€Œæ˜¯ç­‰å¾…â€œå²å®˜â€æ¥è®°å½•
        self.is_thinking = False

    def _find_pareto_front(self, action_vectors: List[Tuple[ActionOption, Dict[str, float]]]) -> List[Tuple[ActionOption, Dict[str, float]]]:
        pareto_front = []
        for i, (action1, vector1) in enumerate(action_vectors):
            is_dominated = False
            for j, (action2, vector2) in enumerate(action_vectors):
                if i == j: continue
                if all(vector2.get(dim, 0) >= vector1.get(dim, 0) for dim in vector1) and any(vector2.get(dim, 0) > vector1.get(dim, 0) for dim in vector1):
                    is_dominated = True
                    break
            if not is_dominated:
                pareto_front.append((action1, vector1))
        return pareto_front

    def _select_from_pareto_front(self, pareto_front: List[Tuple[ActionOption, Dict[str, float]]]) -> ActionOption:
        if not pareto_front: return self.current_dilemma.action_options[0]
        if len(pareto_front) == 1: return pareto_front[0][0]
        best_action = None
        max_final_score = -1
        weights = self.genome.get_intuitions()
        self.thought_stream.add("æ ¹æ®æˆ‘çš„ä¸ªæ€§å’Œæ–‡åŒ–èƒŒæ™¯è¿›è¡Œæœ€ç»ˆæƒè¡¡:", 2)

        for action, vector in pareto_front:
            base_score = sum(vector.get(dim, 0) * weights.get(dim, 0) for dim in ['utilitarian', 'deontological', 'virtue'])
            cultural_adjustment = 0.0
            if weights.get('power_distance', 0.5) > CULTURAL_INFLUENCE_THRESHOLD:
                cultural_adjustment += vector.get('deontological', 0) * (weights['power_distance'] - 0.5) * CULTURAL_ADJUSTMENT_FACTOR
            individualism_score = weights.get('individualism', 0.5)
            if individualism_score < (1 - CULTURAL_INFLUENCE_THRESHOLD):
                cultural_adjustment += vector.get('utilitarian', 0) * (0.5 - individualism_score) * CULTURAL_ADJUSTMENT_FACTOR
            elif individualism_score > CULTURAL_INFLUENCE_THRESHOLD:
                cultural_adjustment += vector.get('virtue', 0) * (individualism_score - 0.5) * CULTURAL_ADJUSTMENT_FACTOR
            if weights.get('uncertainty_avoidance', 0.5) > CULTURAL_INFLUENCE_THRESHOLD:
                uncertainty_penalty = action.metadata.get('uncertainty_score', 0.0) * (weights['uncertainty_avoidance'] - 0.5) * CULTURAL_ADJUSTMENT_FACTOR
                cultural_adjustment -= uncertainty_penalty
            final_score = base_score + cultural_adjustment
            self.thought_stream.add(f"è¯„ä¼° '{action.name}': åŸºç¡€åˆ†={base_score:.2f}, æ–‡åŒ–è°ƒæ•´={cultural_adjustment:.2f} -> æœ€ç»ˆåˆ†={final_score:.2f}", 3)
            if final_score > max_final_score:
                max_final_score = final_score
                best_action = action
        return best_action

    def face_dilemma(self, case: EthicalCase):
        print(f"\nğŸš¨ {self.name} é‡åˆ°äº†ä¸€ä¸ªæ–°çš„å›°å¢ƒ: '{case.title}'")
        self.current_dilemma = case
        self.is_thinking = True

    def get_genome(self) -> MoralGenome:
        return self.genome

    def set_genome(self, new_genome: MoralGenome):
        self.genome = new_genome

    def get_moral_profile(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "architecture": self.architecture,
            "moral_intuitions": self.genome.get_intuitions(),
        }
